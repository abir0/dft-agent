# API keys for model providers
OPENAI_API_KEY=
CEREBRAS_API_KEY=
ANTHROPIC_API_KEY=
HF_API_KEY=
GROQ_API_KEY=

# Materials project API key
MP_API_KEY=

# Use a fake model for testing
USE_FAKE_MODEL=false

# Set a default model
DEFAULT_MODEL=

# Web server configuration
HOST=0.0.0.0
PORT=8080

# Authentication secret, HTTP bearer token header is required if set
AUTH_SECRET=

# Application mode. If the value is "dev", it will enable uvicorn reload
MODE="dev"

# Langsmith configuration
LANGSMITH_TRACING=false
LANGSMITH_PROJECT="default"
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY=

# Add for running ollama
# OLLAMA_MODEL=llama3.2
# Set OLLAMA_BASE_URL if running service in docker and ollama on local device
# OLLAMA_BASE_URL=http://host.docker.internal:11434

# Agent URL: used in Streamlit app - if not set, defaults to http://{HOST}:{PORT}
# AGENT_URL=http://0.0.0.0:8080

# Database credentials
DATABASE_URL=
